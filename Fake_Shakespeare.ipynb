{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNzjJeqGiYqj1c7Y7VWCz+t",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ulya1202/NLP/blob/main/Fake_Shakespeare.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CtbpZARygPOw"
      },
      "source": [
        "#Generating Shakespearean Text Using a Character RNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N2i-MygPjLVV",
        "outputId": "28844687-4270-43aa-ca1d-507de427d006"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://homl.info/shakespeare\n",
            "\u001b[1m1115394/1115394\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "shakespeare_url = \"https://homl.info/shakespeare\"\n",
        "\n",
        "filepath = tf.keras.utils.get_file(\"shakespeare.txt\",shakespeare_url)\n",
        "with open(filepath) as f:\n",
        "  shakespeare_text = f.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KYE9AsVFjsLP",
        "outputId": "7c3b779b-d8c1-4051-a1f1-d55aae2a4c1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n"
          ]
        }
      ],
      "source": [
        "print(shakespeare_text[:80])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "ScRTeQ1FkQtP",
        "outputId": "506ea4dc-f044-4511-c4e6-5da76ddbf97a"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\n !$&',-.3:;?abcdefghijklmnopqrstuvwxyz\""
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "''.join(sorted(set(shakespeare_text.lower())))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NmJfJW8CkieP"
      },
      "outputs": [],
      "source": [
        "text_vec_layer  = tf.keras.layers.TextVectorization(split='character',\n",
        "                                                    standardize = 'lower')#. vergul lazim\n",
        "text_vec_layer.adapt(shakespeare_text)\n",
        "encoded = text_vec_layer(shakespeare_text)#-elave listun ichinden cixaririq tex vece gonderririk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m6bAneDIlT7v"
      },
      "outputs": [],
      "source": [
        "encoded -=2 #unkw ve paddingi sil - qiymet ignore edir onunchun 0-2 ve.s\n",
        "vocab_size = text_vec_layer.vocabulary_size() - 2\n",
        "dataset_size = len(encoded)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQfwnT7Ol3Bm",
        "outputId": "3df71bfc-c495-4b12-84ef-2ff0cbc504e5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1115394"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset_size #listin ichinen cixarmasaq 1 olar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UtzNoggzm9MM"
      },
      "outputs": [],
      "source": [
        "#input -> Before we proceed any furthe\n",
        "#output -> efore we proceed any further"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RCb4kSNel49p"
      },
      "outputs": [],
      "source": [
        "def to_dataset(sequence , lenght ,seed =None,shuffle = False,batch_size = 32):\n",
        "  ds = tf.data.Dataset.from_tensor_slices(sequence)\n",
        "  ds = ds.window(lenght+1,shift=1,drop_remainder = True) #qissa daha suretlidi amma kokhne elaqeler unudulur\n",
        "  ds = ds.flat_map(lambda window_ds: window_ds.batch(lenght+1)) #hamisini birleshdirir\n",
        "  if shuffle :\n",
        "    ds = ds.shuffle(100_000,seed=seed) #batchleri qarishdir\n",
        "  ds = ds.batch(batch_size)\n",
        "  return ds.map(lambda window:(window[:,:-1],window[:,1:]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YEBT-y1CnzqE"
      },
      "outputs": [],
      "source": [
        "lenght = 100\n",
        "tf.random.set_seed(42)\n",
        "train_set = to_dataset(encoded[:1_000_000],lenght=lenght,shuffle=True,\n",
        "                       seed=42)\n",
        "valid_set = to_dataset(encoded[1_000_000:1_060_000],lenght=lenght)\n",
        "test_set = to_dataset(encoded[1_060_000:],lenght=lenght)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-qQ2J-CRoat8",
        "outputId": "cc16cbe5-026c-459a-cb87-bf55cdb2bad3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  31244/Unknown \u001b[1m401s\u001b[0m 12ms/step - accuracy: 0.5485 - loss: 1.4933"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/epoch_iterator.py:151: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self._interrupted_warning()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
            "\u001b[1m31247/31247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m417s\u001b[0m 13ms/step - accuracy: 0.5485 - loss: 1.4933 - val_accuracy: 0.5337 - val_loss: 1.6072\n"
          ]
        }
      ],
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(input_dim = vocab_size,output_dim=16), #bir herifi ifade etmek uchun kifayetdi\n",
        "    tf.keras.layers.GRU(128,return_sequences = True), #y- i return etsin  hamisinda cixir\n",
        "    tf.keras.layers.Dense(vocab_size,activation=\"softmax\") #her neyron bir herif\n",
        "])\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\",optimizer=\"nadam\",\n",
        "              metrics = [\"accuracy\"])\n",
        "\n",
        "model_ckpt = tf.keras.callbacks.ModelCheckpoint(\n",
        "    \"my_shakespeare_model.keras\",\n",
        "    monitor=\"val_accuracy\",\n",
        "    save_best_only = True)\n",
        "\n",
        "history = model.fit(train_set,validation_data=valid_set,epochs=1,\n",
        "                    callbacks=[model_ckpt])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-dm3NSWlp3SC"
      },
      "outputs": [],
      "source": [
        "shakespeare_model = tf.keras.Sequential([ #test uchun\n",
        "    text_vec_layer,\n",
        "    tf.keras.layers.Lambda(lambda X:X-2), #paddingle baqli pad unk\n",
        "    model\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "I8Rgia0KrxWX",
        "outputId": "44eba7b3-8006-468c-d82a-81af11bd7f62"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "np.str_('e')"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_proba = shakespeare_model.predict(tf.constant([\"To be or not to b\"]))[0,-1] #en axirinci herifi qaytarmisr !!!\n",
        "y_pred = tf.argmax(y_proba)\n",
        "text_vec_layer.get_vocabulary()[y_pred+2] #unk ve pad"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LiqPgndIYNHd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QauT60V2s6-w"
      },
      "source": [
        "#Generating Fake Shakespeare text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k4FSm_7xuI8l",
        "outputId": "cc9a13ea-626f-4139-b138-3875856baf8a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 8), dtype=int64, numpy=array([[0, 0, 0, 1, 0, 0, 0, 1]])>"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "log_probas = tf.math.log([[0.5,0.3,0.2]])\n",
        "tf.random.categorical(log_probas,num_samples=8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l1UB7UpioihX"
      },
      "outputs": [],
      "source": [
        "#\"Bu log ehtimallardan istifadə et, və 8 dəfə təsadüfi kateqoriya seç\"\n",
        "\n",
        "#Yəni, 0.5 ehtimalla 0, 0.3 ilə 1, 0.2 ilə 2 gələcək."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tjyhBsI3mgQo",
        "outputId": "ed04122d-1d67-4a0a-a898-450fa154a73e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(14, 39)"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "shakespeare_model.predict(tf.constant(['hello my dearr']))[0].shape #cumledeki charekterler setirde -- yeni h-dan sonra hansi l dan sonra hansi ve.s --> butun vocabulary uzre"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I4zyzVsboeCL"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IAY93FqsnK5x",
        "outputId": "88a8d7bd-12c1-47b5-de44-995ef2a67dbe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[3.69505249e-02, 2.75135607e-01, 2.76962855e-05, 1.36351194e-02,\n",
              "        3.04775499e-02, 1.35534242e-01, 2.32875591e-05, 5.54100983e-02,\n",
              "        2.10383977e-03, 4.07455673e-06, 4.97320257e-02, 2.53603503e-04,\n",
              "        1.09040855e-04, 2.61573605e-02, 1.83994329e-04, 5.41657768e-02,\n",
              "        1.11590640e-03, 2.45396625e-02, 2.06100231e-04, 4.77084331e-03,\n",
              "        1.47981060e-04, 3.30972427e-04, 1.33541116e-05, 2.35887337e-03,\n",
              "        8.31076704e-07, 1.48155232e-05, 2.57752016e-02, 2.22173974e-01,\n",
              "        1.06029818e-02, 3.89179611e-03, 2.26366110e-02, 1.50033308e-03,\n",
              "        7.92848459e-06, 9.41146993e-07, 6.91933155e-06, 1.17855791e-07,\n",
              "        1.12989778e-08, 5.74992365e-09, 1.53976040e-12]], dtype=float32)"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "shakespeare_model.predict(tf.constant(['hello my dearr']))[0,-1:]#noqtesizde eyni neticeni verdi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BF04GxeAuctx"
      },
      "outputs": [],
      "source": [
        "def next_char(text,temperature):\n",
        "  text = tf.constant([text])\n",
        "  y_proba = shakespeare_model.predict(text)[0,-1:]# niye iki noqte\n",
        "  rescaled_logits = tf.math.log(y_proba)/temperature\n",
        "  char_id = tf.random.categorical(rescaled_logits,num_samples=1)[0,0]# iki moteroized qurtaramq uchun\n",
        "  return text_vec_layer.get_vocabulary()[char_id+2] #chartcertid tapidi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "er2bJTTbvspH"
      },
      "outputs": [],
      "source": [
        "def extent_text(text,chars=50,temperature = 1):\n",
        "  for _ in range(chars):\n",
        "    text +=next_char(text,temperature)\n",
        "  return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AV7OO7pxxR-x"
      },
      "outputs": [],
      "source": [
        "extent_text('to be or not to be',chars = 100,temperature = 1)"
      ]
    }
  ]
}